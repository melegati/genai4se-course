{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03e8b870-e6fc-4bf5-a1bb-cf876a5f1591",
   "metadata": {
    "id": "03e8b870-e6fc-4bf5-a1bb-cf876a5f1591"
   },
   "source": [
    "# Function calling\n",
    "\n",
    "In this example, we will use function calling (tools) to obtain information from a Git repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40f1eee-0d53-4a01-a5cf-9f7ed65cfb57",
   "metadata": {
    "id": "c40f1eee-0d53-4a01-a5cf-9f7ed65cfb57"
   },
   "source": [
    "## Dependencies\n",
    "\n",
    "We will use LangChain again and we also need GitPython to interact with a Git repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4f7765-d1d6-4aad-8ba6-160751c0d6dc",
   "metadata": {
    "id": "5b4f7765-d1d6-4aad-8ba6-160751c0d6dc"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install GitPython langchain-openai langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b9c8cb-503b-479f-8057-a0980afd0df8",
   "metadata": {
    "id": "f4b9c8cb-503b-479f-8057-a0980afd0df8"
   },
   "source": [
    "## Model\n",
    "\n",
    "We will use an OpenAI model again, so we need an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f612f9-8495-48c9-8013-acc4b0880fb5",
   "metadata": {
    "id": "91f612f9-8495-48c9-8013-acc4b0880fb5"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fN-6KN_xEhmJ",
   "metadata": {
    "id": "fN-6KN_xEhmJ"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/rjust/defects4j.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b168e7b6-a9dc-458b-9dff-5b66d6e8a898",
   "metadata": {
    "id": "b168e7b6-a9dc-458b-9dff-5b66d6e8a898"
   },
   "source": [
    "## Defining the functions\n",
    "\n",
    "Let's define the functions (tools) that can be called to fulfill a task sent to the model.\n",
    "\n",
    "It is important to give informative names for the function and the parameters and provide some form of documentation. These details will be provided in the context of the query to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d9705-6d0b-42e1-86a8-114696e6aa5a",
   "metadata": {
    "id": "a26d9705-6d0b-42e1-86a8-114696e6aa5a"
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from typing import List\n",
    "from langchain_core.tools import tool\n",
    "from git import Git\n",
    "\n",
    "repo_directory = './defects4j'\n",
    "\n",
    "@tool\n",
    "def list_commits_between(start_date: date, end_date: date) -> str:\n",
    "    \"\"\" Returns the messages of the commits from an interval between dates.\n",
    "    Args:\n",
    "        start_date: The start of the interval.\n",
    "        end_date: The end of the date.\n",
    "    \"\"\"\n",
    "    repo = Git(repo_directory)\n",
    "    logs = repo.log('--since={}'.format(start_date), '--until={}'.format(end_date), '--oneline')\n",
    "    return logs\n",
    "\n",
    "@tool\n",
    "def list_commits_from(contributor: str) -> str:\n",
    "  \"\"\" Returns the commits from a specific contributor.\n",
    "  Args:\n",
    "      contributor: The name of the contributor.\n",
    "  \"\"\"\n",
    "  repo = Git(repo_directory)\n",
    "  logs = repo.log('--author={}'.format(contributor))\n",
    "  return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5f2346-ef42-4393-a1cb-f82bd712ff92",
   "metadata": {
    "id": "1a5f2346-ef42-4393-a1cb-f82bd712ff92"
   },
   "source": [
    "## Binding the functions to the model\n",
    "\n",
    "Now, let's register the functions into the model. After that, the calls to the model will inform about the existence of the functions, what they can do and their parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c42041-b083-4ccd-99ac-b56e69a0f153",
   "metadata": {
    "id": "f5c42041-b083-4ccd-99ac-b56e69a0f153"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools([list_commits_between, list_commits_from])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68489638-9791-44a8-a569-45ea2ad9aaeb",
   "metadata": {
    "id": "68489638-9791-44a8-a569-45ea2ad9aaeb"
   },
   "source": [
    "## Querying the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2c1f7d-1077-4f3d-93b9-920f84b12f83",
   "metadata": {
    "id": "af2c1f7d-1077-4f3d-93b9-920f84b12f83"
   },
   "source": [
    "Let's ask the model to summarize what was done in the project in the last year.\n",
    "\n",
    "To do so, we have to tell the model the date of today (do you want to try without doing so?))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab14fee0-cd80-4d6d-b19d-c0a1e4df668b",
   "metadata": {
    "id": "ab14fee0-cd80-4d6d-b19d-c0a1e4df668b"
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "query = '''Summarize what has been done in the project last calendar year. Today is {}.\n",
    "          In your answer, provide the dates of which your results refer to.'''.format(date.today())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e4937a-6e1f-4ac6-a4bb-5a66e67b1fed",
   "metadata": {
    "id": "b5e4937a-6e1f-4ac6-a4bb-5a66e67b1fed"
   },
   "source": [
    "Now let's query the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df65dbf6-a4b6-49cf-a5dd-82d763d38020",
   "metadata": {
    "id": "df65dbf6-a4b6-49cf-a5dd-82d763d38020"
   },
   "outputs": [],
   "source": [
    "msg_with_tool_calls = llm_with_tools.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea719668-b568-4e38-87db-0349443b6638",
   "metadata": {
    "id": "ea719668-b568-4e38-87db-0349443b6638"
   },
   "source": [
    "Let's inspect the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba0db10-ccdb-426a-a1e7-abd6bbb8f809",
   "metadata": {
    "id": "aba0db10-ccdb-426a-a1e7-abd6bbb8f809"
   },
   "outputs": [],
   "source": [
    "msg_with_tool_calls.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f25bbf5-197d-4fbb-8a65-d9e8cc635f50",
   "metadata": {
    "id": "5f25bbf5-197d-4fbb-8a65-d9e8cc635f50"
   },
   "source": [
    "Now, we have to pass the previous messages to the model. Let's prepare the list of messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6860aed7-542e-48a0-b550-4bffb2f17516",
   "metadata": {
    "id": "6860aed7-542e-48a0-b550-4bffb2f17516"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = [HumanMessage(query), msg_with_tool_calls]\n",
    "\n",
    "for tool_call in msg_with_tool_calls.tool_calls:\n",
    "    selected_tool = locals()[tool_call['name']]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "    tool_msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dc05de-176a-4370-bf94-187dd829225a",
   "metadata": {
    "id": "e9dc05de-176a-4370-bf94-187dd829225a"
   },
   "source": [
    "Now, it is time to send to the model and see the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab3cafb-a25a-4da6-966a-e315b62f1cce",
   "metadata": {
    "id": "0ab3cafb-a25a-4da6-966a-e315b62f1cce"
   },
   "outputs": [],
   "source": [
    "result = llm_with_tools.invoke(messages)\n",
    "result.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22238d54-4c06-4b06-bc64-8e55090818ce",
   "metadata": {
    "id": "22238d54-4c06-4b06-bc64-8e55090818ce"
   },
   "source": [
    "## Exercise\n",
    "\n",
    "1. Modify the code to ask about a specific contributor."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
